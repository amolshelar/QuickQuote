{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# File imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "import re\n",
    "from datetime import datetime\n",
    "#from search_term import give_med_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number = r'\\d{2,3}'\n",
    "gender = r'(\\b[Mm]ale?)|(\\b[Ff]emale?)|(\\bFEMALE)|(\\bMALE)|(/b)|F/|M/'\n",
    "Date = r'(([A-Z0-9][A-Z0-9]?[/-])?[A-Z0-9][A-Z0-9]?[/-][A-Z0-9][A-Z0-9][A-Z0-9]?[A-Z0-9]?)|([A-Za-z][A-Za-z][A-Za-z]\\s..?[,]\\s....)'\n",
    "DOB  = r'(.*)?DOB|[Dd][aA][tT][eE]\\s[oO][fF]\\s[Bb][iI][rR][tT][hH]\\s?(.*)?'\n",
    "year_four_digit = r'\\b(19|20)\\d{2}(w+)?'\n",
    "year_two_digit = r'\\d{2}$(w+)?'\n",
    "product_type = r'(\\b[Pp]roduct\\s[Tt]ype):\\s?.*'\n",
    "permanent = r'[Pp][eE][rR][mM]([aA][nN][aA][nN][tT])?'\n",
    "term = r'[tT][eE][rR][mM]'\n",
    "\n",
    "#Assuming USA currency dollar\n",
    "amount_with_dollar = r'(\\$\\s?\\d{1,3}(,\\d{2,3})*(\\.\\d+)?)(\\s?[kK]?)(\\s?[mM]?[mM]?(illion)?(ILLION)?)([bB]?)'\n",
    "amount_without_dollar = r'(\\$?\\s?\\d{1,3}(,\\d{2,3})*(\\.\\d+)?)(\\s?[kK]?)(\\s[mM]?[mM]?(illion)?(ILLION)?)([bB]?)((\\s?[Yy][Ee][aA][rR][sS]?)?)'\n",
    "faceamount = r'(\\b[Ff]ace\\s?[Aa]mount:?\\s?.*)'\n",
    "termamount = r'(.*)?[Tt][eE][rR][mM](.*)?'   \t\t\t#Regex to read single line from first newline to next newline\n",
    "seeking = r'(.*)?[Ss][eE][eE][kK]([iI][nN][gG])?(.*)?'\n",
    "term_year = r'(y(ea)?r|Y(ea)?r|Y(ea)?r)'\n",
    "k_conv = r'(\\s?[kK])'\n",
    "m_conv = r'(\\s?[mM][mM]?(illion)?(ILLION)?)'\n",
    "num_conv = r'\\d{1,3}'\n",
    "\n",
    "weight = r'(.*)?\\b[wW][eE][iI][gG][hH][tT]\\s?(.*)?' \n",
    "weight_num = r'(\\d*\\.?\\d+)\\s?(lb|lbs|Lbs|LB|LBS|kg|Kg|KG|#)'\t\t#r'(.*)\\s?([lL][bB][sS]|[oO][zZ]|[gG]|[kK][Gg])' \n",
    "\n",
    "age_simple = r'(.*)?[Aa][Gg][Ee]\\s?(.*)?'\n",
    "age = r'(.*\\s?[Yy]([eE][aA])?[rR]?[sS]?\\s?([oO][lL][dD])?)'\n",
    "age_from_gender = r'(.*)?(\\b[Mm]ale?)|(\\b[Ff]emale?)|(\\bFEMALE)|(\\bMALE)|(/b)\\s?(.*)?' \n",
    "\n",
    "height_num = r'\\d{1,2}'\n",
    "height1 = r'((.*)?\\s?([Ff][eE][eE][tT])((.*)?\\s?([iI][nN][Cc][Hh][Ee][Ss]))?)'\n",
    "height2 = r'.[\\'|\\’](\\s?.[\\\"|\\”])?' \n",
    "feet = r'\\d[\\'|\\’]'\n",
    "inches = r'\\d[\\\"|\\”]' \n",
    "\n",
    "preferred = r'(.*)?(Preferred|preferred)\\s?(.*)?'\n",
    "height_word = r'Height|height'\n",
    "weight_word = r'Weight|weight' \n",
    "\n",
    "build = r'(Build|build)\\s?(.*)?'\n",
    "build_weight = r'\\d{3}'\n",
    "build_height = r'\\d\\.\\d'\n",
    "\n",
    "smoker = r'(.*)?[sS][Mm][oO][Kk]\\s?(.*)?' \n",
    "tobacco = r'(.*)?[Tt][oO][bB][aA][cC][cC][oO]\\s?(.*)?'\n",
    "no = r'[nN][oO]'\n",
    "\n",
    "med = r'(.*)?\\b[mM][eE][dD][iI][cC][aA][tT][iI][oO][nN]\\s?(.*)?'\n",
    "\n",
    "family = r'(.*)?(\\b[Ff]amily)\\s?(.*)?'\n",
    "family_member = r'(.*)?(\\b[Mm]om)|(\\b[Ff]ather)|(\\b[Dd]ad)|(\\b[Ss]ister)|(\\b[Bb]rother)|(\\b[Hh]usband)|(\\b[Ww]ife)\\s?(.*)?'\n",
    "\n",
    "lives = r'(.*)?(\\b[Ll]ives)\\s?(.*)?'\n",
    "prop = r'(.*)?(\\b[Pp]roperty)\\s?(.*)?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg(st,i):\n",
    "    for line in st: #iterate through every line\n",
    "        #return list of entities in that line\n",
    "        num = re.search(number, line, re.I | re.U)\n",
    "        x=0\n",
    "        x = re.search(Date, line, re.I | re.U)\n",
    "#Gender\n",
    "        y = re.search(gender, line, re.I | re.U)\n",
    "        if(y):\n",
    "            if(y.group(0)=='F/' or y.group(0)=='f/'):\n",
    "                data[i][0]='Female'\n",
    "            elif(y.group(0)=='M/' or y.group(0)=='m/'):\n",
    "                data[i][0]='Male'\n",
    "            else:\n",
    "\n",
    "                data[i][0]=(y.group(0))\n",
    "        elif(y and num):\n",
    "            data[i][0]=(y.group(0))\n",
    "        else:\n",
    "            data[i][0]=\" \"\n",
    "\n",
    "#Year for DOB\n",
    "        z = 0\n",
    "        x1 = re.search(year_four_digit, line, re.I | re.U)\n",
    "        if(x):\n",
    "            x1 = re.search(year_four_digit, x.group(0), re.I | re.U)\n",
    "            x2 = re.search(year_two_digit, x.group(0), re.I | re.U)\n",
    "            if(x1):\n",
    "                data[i][1]=x1.group(0)\n",
    "            elif(x2):\n",
    "                z = x2.group(0)\n",
    "                data[i][1] = '19'+z\n",
    "        elif(x1):\n",
    "            x1 = re.search(year_four_digit, line, re.I | re.U)\n",
    "\n",
    "            data[i][1]=x1.group(0)\n",
    "        else:\n",
    "            data[i][1]=\" \"\n",
    "\n",
    "#Age in years\n",
    "        age_reg = re.search(age, line, re.I | re.U)\n",
    "        age_simple_reg = re.search(age_simple, line, re.I | re.U)\n",
    "        dob = re.search(DOB, line, re.I | re.U)\n",
    "        age_gender_reg = re.search(age_from_gender, line, re.I | re.U)\n",
    "\n",
    "        if(age_gender_reg):\n",
    "                am = re.search(number, age_gender_reg.group(0), re.I | re.U)\n",
    "                if(am):\n",
    "                    data[i][2]=am.group(0)\n",
    "\n",
    "        if(x1):#20/03/1996\n",
    "\n",
    "            currentYear = datetime.now().year\n",
    "\n",
    "            data[i][2]=((currentYear-(int)(x1.group(0))))\n",
    "\n",
    "        else:\n",
    "            if(x1 and dob):#DOB 20/03/1996\n",
    "\n",
    "                currentYear = datetime.now().year\n",
    "\n",
    "                data[i][2]=((currentYear-(int)(x1.group(0))))\n",
    "            elif(x1 and y):#Male 20/03/1996\n",
    "\n",
    "                currentYear = datetime.now().year\n",
    "\n",
    "                data[i][2]=((currentYear-(int)(x1.group(0))))\n",
    "\n",
    "            else:\n",
    "                data[i][2]=' '\n",
    "\n",
    "            if(age_reg):#20 years ago\n",
    "                age_num = age_reg.group(0)\n",
    "                an = re.search(number, age_num, re.I | re.U)\n",
    "                if(an):\n",
    "\n",
    "                    data[i][2]=(an.group(0))\n",
    "\n",
    "            if(age_simple_reg):#Age 20\n",
    "                age_num = age_simple_reg.group(0)\n",
    "                an = re.search(number, age_num, re.I | re.U)\n",
    "                if(an):\n",
    "\n",
    "                    data[i][2]=(an.group(0))\n",
    "\n",
    "            if((data[i][2]<'18') and data[i][1]!=\" \"):#From Year of Birth\n",
    "                currentYear = datetime.now().year\n",
    "                data[i][2]=(currentYear-(int)(data[i][1]))\n",
    "\n",
    "#Product Type\n",
    "        z=re.search(product_type, line, re.I | re.U)\n",
    "        perm_reg = re.search(permanent, line, re.I | re.U)\n",
    "        term_type_reg = re.search(term, line, re.I | re.U)\n",
    "        if(z): \n",
    "\n",
    "            data[i][3]=(z.group(0))\n",
    "        elif(perm_reg):\n",
    "            final_str = \"Product Type: Permanent\"\n",
    "            data[i][3]=(final_str)\n",
    "        elif(term_type_reg):\n",
    "            final_str = \"Product Type: Term\"\n",
    "            data[i][3]=(final_str)\n",
    "        else:\n",
    "            data[i][3]=\" \"\n",
    "            \n",
    "        w = re.search(faceamount, line, re.I | re.U)\n",
    "        term_reg = re.search(termamount, line, re.I | re.U)\n",
    "        seek_reg = re.search(seeking, line, re.I | re.U)\n",
    "#With faceAmount\n",
    "        if(w):\n",
    "            k = re.search(k_conv, w.group(0), re.I | re.U)\n",
    "            if(k):\n",
    "                nn = re.search(num_conv, w.group(0), re.I | re.U)\n",
    "                if(nn):\n",
    "                    data[i][4]='Face Amount: $'+((nn.group(0))+',000')\n",
    "            else:\n",
    "                data[i][4]=(w.group(0))\n",
    "\n",
    "\n",
    "#With term Amount\n",
    "        elif(term_reg):\n",
    "            amd = re.search(amount_with_dollar, term_reg.group(0), re.I | re.U)\n",
    "            amwd = re.search(amount_without_dollar, term_reg.group(0), re.I | re.U)\t\t\t#Find 2nd regex in the same line of 1st regex \n",
    "            z = 0\n",
    "            if(amd):\n",
    "                k = re.search(k_conv, amd.group(0), re.I | re.U)\n",
    "                m = re.search(m_conv, amd.group(0), re.I | re.U)\n",
    "                if(k):\n",
    "                    nn = re.search(num_conv, amd.group(0), re.I | re.U)\n",
    "                    data[i][4]='Face Amount: '+((nn.group(0))+',000')\n",
    "                elif(m):\n",
    "                    nn = re.search(num_conv, amd.group(0), re.I | re.U)\n",
    "                    data[i][4]='Face Amount: '+((nn.group(0))+',000,000')\n",
    "                else:\n",
    "                    data[i][4]='Face Amount: '+amd.group(0)\n",
    "            elif(amwd):\n",
    "                term_year_reg = re.search(term_year, amwd.group(0), re.I | re.U)\n",
    "                if(term_year_reg):\n",
    "                    data[i][4]='Term Year: '+(amwd.group(0))\n",
    "                else:\n",
    "#data[i][4]='Face Amount: $'+(amwd.group(0))\n",
    "                    k = re.search(k_conv, amwd.group(0), re.I | re.U)\n",
    "                    m = re.search(m_conv, amwd.group(0), re.I | re.U)\n",
    "                    if(k):\n",
    "                        nn = re.search(num_conv, amwd.group(0), re.I | re.U)\n",
    "                        data[i][4]='Face Amount: $'+((nn.group(0))+',000')\n",
    "                    elif(m):\n",
    "                        nn = re.search(num_conv, amwd.group(0), re.I | re.U)\n",
    "                        data[i][4]='Face Amount: $'+((nn.group(0))+',000,000')\n",
    "                    else:\n",
    "                        data[i][4]='Face Amount: $'+amwd.group(0)\n",
    "#With Seeking\n",
    "        elif(seek_reg):\n",
    "            amd = re.search(amount_with_dollar, seek_reg.group(0), re.I | re.U)\n",
    "            amwd = re.search(amount_without_dollar, seek_reg.group(0), re.I | re.U)\t\t\t#Find 2nd regex in the same line of 1st regex \n",
    "            if(amd):\n",
    "#data[i][4]='Face Amount: '+(amd.group(0))\n",
    "                k = re.search(k_conv, amd.group(0), re.I | re.U)\n",
    "                m = re.search(m_conv, amd.group(0), re.I | re.U)\n",
    "                if(k):\n",
    "                    nn = re.search(num_conv, amd.group(0), re.I | re.U)\n",
    "                    data[i][4]='Face Amount: '+((nn.group(0))+',000')\n",
    "                elif(m):\n",
    "                    nn = re.search(num_conv, amd.group(0), re.I | re.U)\n",
    "                    data[i][4]='Face Amount: '+((nn.group(0))+',000,000')\n",
    "                else:\n",
    "                    data[i][4]='Face Amount: '+amd.group(0)\n",
    "            elif(amwd):\n",
    "                term_year_reg = re.search(term_year, amwd.group(0), re.I | re.U)\n",
    "                if(term_year_reg):\n",
    "                    data[i][4]='Term Year: '+(amwd.group(0))\n",
    "                else:\n",
    "#data[i][4]='Face Amount: $'+(amwd.group(0))\n",
    "                    k = re.search(k_conv, amwd.group(0), re.I | re.U)\n",
    "                    m = re.search(m_conv, amwd.group(0), re.I | re.U)\n",
    "                    if(k):\n",
    "                        nn = re.search(num_conv, amwd.group(0), re.I | re.U)\n",
    "                        data[i][4]='Face Amount: $'+((nn.group(0))+',000')\n",
    "                    elif(m):\n",
    "                        nn = re.search(num_conv, amwd.group(0), re.I | re.U)\n",
    "                        data[i][4]='Face Amount: $'+((nn.group(0))+',000,000')\n",
    "                    else:\n",
    "                        data[i][4]='Face Amount: $'+amwd.group(0)\n",
    "        else:\n",
    "            data[i][4]=\" \"\n",
    "\n",
    "\n",
    "#Weight\n",
    "        x=re.search(weight_num, line, re.I | re.U) \n",
    "        wt=re.search(weight, line, re.I | re.U)\n",
    "        if(x): \n",
    "#print (x.group(0)+\"\\n\")\n",
    "            data[i][5]=(x.group(0))\n",
    "        elif(wt):\n",
    "            am = re.search(weight_num,wt.group(0), re.I | re.U)\n",
    "            if(am):\n",
    "                data[i][5]=(am.group(0))\n",
    "        else:\n",
    "            data[i][5]=\" \"\n",
    "\n",
    "#Height\n",
    "        ht = re.search(height1, line, re.I | re.U)\n",
    "        htsym = re.search(height2, line, re.I | re.U)\n",
    "        if(ht): \n",
    "\n",
    "            data[i][6]=(ht.group(0))\n",
    "        elif(htsym):\n",
    "            f = re.search(feet, (htsym.group(0)), re.I | re.U)\n",
    "            inch = re.search(inches, (htsym.group(0)), re.I | re.U)\n",
    "            if(f):\n",
    "\n",
    "                am = re.search(height_num, (f.group(0)), re.I | re.U).group(0) + ' Feet'\n",
    "                if(i):\n",
    "                    am+=re.search(height_num, (inch.group(0)), re.I | re.U).group(0) + ' Inches' \n",
    "                data[i][6]=am\n",
    "        else:\n",
    "            data[i][6]=\" \"\n",
    "\n",
    "#Preferred Height & Weight\n",
    "        pr = ''\n",
    "        pr = re.search(preferred, line, re.I | re.U)\n",
    "        if(pr!='' and pr):\n",
    "            h_reg = re.search(height_word, pr.group(0), re.I | re.U)\n",
    "            if(h_reg):\n",
    "                data[i][6] = \"5 Feet 9 Inches\"\n",
    "            w_reg = re.search(weight_word, pr.group(0), re.I | re.U)\n",
    "            if(w_reg):\n",
    "                data[i][5] = \"196 lbs\"\n",
    "\n",
    "#Height & Weight from build\n",
    "        bu = ''\n",
    "        bu = re.search(build, line, re.I | re.U)\n",
    "        if(bu):\n",
    "            h_reg = re.search(build_height, bu.group(0), re.I | re.U)\n",
    "            if(h_reg):\n",
    "                data[i][6] = h_reg.group(0) + ' Feet'\n",
    "                h =' '\n",
    "            w_reg = re.search(build_weight, bu.group(0), re.I | re.U)\n",
    "            if(w_reg):\n",
    "                data[i][5] = w_reg.group(0)+ ' lbs'\n",
    "                w = ' '\n",
    "\n",
    "#Habit\n",
    "        sm = re.search(smoker, line, re.I | re.U)\n",
    "        tob = re.search(tobacco, line, re.I | re.U)\n",
    "        if(sm): \n",
    "            if(re.search(no, sm.group(0), re.I | re.U)):\n",
    "                data[i][7]=\"Non-Smoker\"\n",
    "            else:\n",
    "                data[i][7]=\"Smoker\"\n",
    "        elif(tob):\n",
    "\n",
    "            if(re.search(no, tob.group(0), re.I | re.U)):\n",
    "                data[i][7]=\"Non-Tobacco\"\n",
    "            else:\n",
    "                data[i][7]=\"Tobacco\"\n",
    "        else:\n",
    "            data[i][7]=\" \"\n",
    "\n",
    "\n",
    "#Medication & Treatment\n",
    "        med_reg = (re.search(med,line, re.I | re.U))\n",
    "        if(med_reg):\n",
    "            if(re.search(no, med_reg.group(0), re.I | re.U)):\n",
    "                data[i][8]=\"No Medication\"\n",
    "                \n",
    "        else:#Write else outsite condition (to stop rewriting of above cell)\n",
    "            data[i][8]=\"\"\n",
    "\n",
    "#Family\n",
    "        family_reg = (re.search(family,line, re.I | re.U))\n",
    "        family_member_reg = (re.search(family_member,line, re.I | re.U))\n",
    "        if(family_reg):\n",
    "            data[i][9]=family_reg.groups()\n",
    "            \n",
    "        else:#Write else outsite condition (to stop rewriting of above cell)\n",
    "            data[i][9]=\"\"\n",
    "\n",
    "#Property\n",
    "        lives_reg = (re.search(lives,line, re.I | re.U))\n",
    "        prop_reg = (re.search(prop,line, re.I | re.U))\n",
    "        if(lives_reg):\n",
    "            data[i][10]=lives_reg.groups()\n",
    "            if(prop_reg):\n",
    "                data[i][10]=lives_reg.groups()+prop_reg.groups()\n",
    "        elif(prop_reg):\n",
    "            data[i][10]=prop_reg.groups()\n",
    "            \n",
    "        else:#Write else outsite condition (to stop rewriting of above cell)\n",
    "            data[i][10]=\"\"\n",
    "\n",
    "    data[i][11]=st\n",
    "#medical data\n",
    "        #data[i][11] = give_med_terms(line)\n",
    "\n",
    "    wtr.writerows(data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i=0\n",
    "w, h = 12, 1;\n",
    "data = [[\" \" for x in range(w)] for y in range(h)]\n",
    "st = []\n",
    "\n",
    "out = open('regexProcessed.csv', 'w', newline='')\n",
    "wtr= csv.writer( out )\n",
    "wtr.writerow(['Gender','Year_of_birth','Age(years)','Product Type','Face Amount','Weight','Height','Habit','Medication','Family','Property',''])\n",
    "\n",
    "\n",
    "\n",
    "with open('raw_data1.csv','r',encoding=\"ISO-8859-1\") as f:\n",
    "    rows = csv.reader(f)\n",
    "    for row in rows:\n",
    "\n",
    "        st.append(row[8])\n",
    "        reg(st,i)\n",
    "        st=[]\n",
    "          \n",
    "\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Year_of_birth</th>\n",
       "      <th>Age(years)</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Face Amount</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Habit</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Family</th>\n",
       "      <th>Property</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>1977</td>\n",
       "      <td>41</td>\n",
       "      <td>Product Type: Permanent</td>\n",
       "      <td>Face Amount: 50,000</td>\n",
       "      <td>200KG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Gender: FEMALE\\nDOB : APR 20, 1977\\nProduct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>1921</td>\n",
       "      <td>97</td>\n",
       "      <td></td>\n",
       "      <td>Face Amount: 250,000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Gender: male\\nDOB : 10/00/1921\\nFace Amount:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>1997</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>200 lb</td>\n",
       "      <td>5 Feet</td>\n",
       "      <td></td>\n",
       "      <td>No Medication</td>\n",
       "      <td>('No significant ', 'family', 'history')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Male\\n01/31/97\\n5' 6Ó\\n200 lb\\nNo medication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>1945</td>\n",
       "      <td>73</td>\n",
       "      <td></td>\n",
       "      <td>Face Amount: $20,000</td>\n",
       "      <td>199#</td>\n",
       "      <td>8 Feet</td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Family', 'hx of RA in Mother and Sister....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Seeking $20,000 LN offered Table C due to ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Product Type: Permanent</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Male 53\\nBuilt â\\x80\\x93 Preferred NT\\nDiagn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Female</td>\n",
       "      <td>1966</td>\n",
       "      <td>52</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: $500,212</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('Strong ', 'family', 'history for skin cancer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['General:\\n    -   Client Gender: Female\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Female</td>\n",
       "      <td>1996</td>\n",
       "      <td>22</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: 50,000,000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Lives', 'in XXXX XXXX, She is a US Citiz...</td>\n",
       "      <td>['Female, DOB 01/03/1996NS looking for $50m te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MALE</td>\n",
       "      <td>1950</td>\n",
       "      <td>68</td>\n",
       "      <td></td>\n",
       "      <td>Face Amount: $300,000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] QQ: S BarXXXX\\n\\nPlease ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Female</td>\n",
       "      <td>1950</td>\n",
       "      <td>68</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>255lb</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] Pascarella Case - Potent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Female</td>\n",
       "      <td>1950</td>\n",
       "      <td>35</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: $777,000</td>\n",
       "      <td>199 lbs</td>\n",
       "      <td>6.6 Feet</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('Household income is 11K, she is a home maker...</td>\n",
       "      <td>['Subject: [External] XXXXX\\n\\nF/age 35, NS, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Male</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: $555,000</td>\n",
       "      <td>196 lbs</td>\n",
       "      <td>5 Feet 9 Inches</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('           Uses it for pleasure and business...</td>\n",
       "      <td>[\"Subject: [External] Tentative case \\n\\nAgent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Male</td>\n",
       "      <td></td>\n",
       "      <td>22</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Term Year:  22 years</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Male- 22 years old state of 50 looking for 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Female</td>\n",
       "      <td></td>\n",
       "      <td>33</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External]Female Age 33 \\n\\nThis me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>1995</td>\n",
       "      <td>23</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: $59,000,000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No Medication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] QQ - Zvin\\n\\nPer the age...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Male</td>\n",
       "      <td>1995</td>\n",
       "      <td>55</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: $1,555,000</td>\n",
       "      <td>255 lb</td>\n",
       "      <td>6 Feet</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('Mom had breast cancer at age 65 but all ', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Subject: [External] #secure# Wong quote\\n\\nW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>1995</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['APS SUMMARY\\nPMH: Subarachnoid Bleed 20X2 no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Female</td>\n",
       "      <td>1996</td>\n",
       "      <td>22</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Face Amount: 20,000,000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Lives', 'in XXXX XXXX, She is a US Citiz...</td>\n",
       "      <td>['Subject: [pSpam] DR QQ\\n\\nFemale, DOB 01/XX/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Female</td>\n",
       "      <td>1996</td>\n",
       "      <td>55</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>Term Year: 20 year</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] Quick quote request - FM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Male</td>\n",
       "      <td>1999</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>199#</td>\n",
       "      <td></td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Family', 'hx of RA in Mother and Sister....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['LN offered Table C due to chronic pain histo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender Year_of_birth Age(years)             Product Type  \\\n",
       "1   FEMALE          1977         41  Product Type: Permanent   \n",
       "2     male          1921         97                            \n",
       "3     Male          1997         21                            \n",
       "4     Male          1945         73                            \n",
       "5     Male                           Product Type: Permanent   \n",
       "6   Female          1966         52       Product Type: Term   \n",
       "7   Female          1996         22       Product Type: Term   \n",
       "8     MALE          1950         68                            \n",
       "9   Female          1950         68                            \n",
       "10  Female          1950         35       Product Type: Term   \n",
       "11    Male                                Product Type: Term   \n",
       "12    Male                       22       Product Type: Term   \n",
       "13  Female                       33                            \n",
       "14                  1995         23       Product Type: Term   \n",
       "15    Male          1995         55       Product Type: Term   \n",
       "16                  1995         23                            \n",
       "17  Female          1996         22       Product Type: Term   \n",
       "18  Female          1996         55       Product Type: Term   \n",
       "19    Male          1999         19                            \n",
       "\n",
       "                 Face Amount   Weight           Height        Habit  \\\n",
       "1        Face Amount: 50,000    200KG                                 \n",
       "2       Face Amount: 250,000                                          \n",
       "3                              200 lb           5 Feet                \n",
       "4      Face Amount: $20,000      199#           8 Feet  Non-Tobacco   \n",
       "5                                                                     \n",
       "6      Face Amount: $500,212                                Tobacco   \n",
       "7    Face Amount: 50,000,000                            Non-Tobacco   \n",
       "8      Face Amount: $300,000                                          \n",
       "9                               255lb                                 \n",
       "10     Face Amount: $777,000  199 lbs         6.6 Feet                \n",
       "11     Face Amount: $555,000  196 lbs  5 Feet 9 Inches   Non-Smoker   \n",
       "12      Term Year:  22 years                                          \n",
       "13                                                      Non-Tobacco   \n",
       "14  Face Amount: $59,000,000                                          \n",
       "15  Face Amount: $1,555,000    255 lb           6 Feet   Non-Smoker   \n",
       "16                                                                    \n",
       "17   Face Amount: 20,000,000                                          \n",
       "18        Term Year: 20 year                             Non-Smoker   \n",
       "19                               199#                   Non-Tobacco   \n",
       "\n",
       "       Medication                                             Family  \\\n",
       "1             NaN                                                NaN   \n",
       "2             NaN                                                NaN   \n",
       "3   No Medication           ('No significant ', 'family', 'history')   \n",
       "4             NaN  ('', 'Family', 'hx of RA in Mother and Sister....   \n",
       "5             NaN                                                NaN   \n",
       "6             NaN  ('Strong ', 'family', 'history for skin cancer...   \n",
       "7             NaN                                                NaN   \n",
       "8             NaN                                                NaN   \n",
       "9             NaN                                                NaN   \n",
       "10            NaN                                                NaN   \n",
       "11            NaN                                                NaN   \n",
       "12            NaN                                                NaN   \n",
       "13            NaN                                                NaN   \n",
       "14  No Medication                                                NaN   \n",
       "15            NaN  ('Mom had breast cancer at age 65 but all ', '...   \n",
       "16            NaN                                                NaN   \n",
       "17            NaN                                                NaN   \n",
       "18            NaN                                                NaN   \n",
       "19            NaN  ('', 'Family', 'hx of RA in Mother and Sister....   \n",
       "\n",
       "                                             Property  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7   ('', 'Lives', 'in XXXX XXXX, She is a US Citiz...   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10  ('Household income is 11K, she is a home maker...   \n",
       "11  ('           Uses it for pleasure and business...   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17  ('', 'Lives', 'in XXXX XXXX, She is a US Citiz...   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "                                          Unnamed: 11  \n",
       "1   ['Gender: FEMALE\\nDOB : APR 20, 1977\\nProduct ...  \n",
       "2   ['Gender: male\\nDOB : 10/00/1921\\nFace Amount:...  \n",
       "3   [\"Male\\n01/31/97\\n5' 6Ó\\n200 lb\\nNo medication...  \n",
       "4   [\"Seeking $20,000 LN offered Table C due to ch...  \n",
       "5   ['Male 53\\nBuilt â\\x80\\x93 Preferred NT\\nDiagn...  \n",
       "6   ['General:\\n    -   Client Gender: Female\\n   ...  \n",
       "7   ['Female, DOB 01/03/1996NS looking for $50m te...  \n",
       "8   ['Subject: [External] QQ: S BarXXXX\\n\\nPlease ...  \n",
       "9   ['Subject: [External] Pascarella Case - Potent...  \n",
       "10  ['Subject: [External] XXXXX\\n\\nF/age 35, NS, b...  \n",
       "11  [\"Subject: [External] Tentative case \\n\\nAgent...  \n",
       "12  ['Male- 22 years old state of 50 looking for 2...  \n",
       "13  ['Subject: [External]Female Age 33 \\n\\nThis me...  \n",
       "14  ['Subject: [External] QQ - Zvin\\n\\nPer the age...  \n",
       "15  [\"Subject: [External] #secure# Wong quote\\n\\nW...  \n",
       "16  ['APS SUMMARY\\nPMH: Subarachnoid Bleed 20X2 no...  \n",
       "17  ['Subject: [pSpam] DR QQ\\n\\nFemale, DOB 01/XX/...  \n",
       "18  ['Subject: [External] Quick quote request - FM...  \n",
       "19  ['LN offered Table C due to chronic pain histo...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"regexProcessed.csv\", encoding='ISO-8859-1')\n",
    "df = df.iloc[1:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                50000\n",
       "2               250000\n",
       "3                     \n",
       "4                20000\n",
       "5                     \n",
       "6               500212\n",
       "7             50000000\n",
       "8               300000\n",
       "9                     \n",
       "10              777000\n",
       "11              555000\n",
       "12    TermYear:22years\n",
       "13                    \n",
       "14            59000000\n",
       "15             1555000\n",
       "16                    \n",
       "17            20000000\n",
       "18     TermYear:20year\n",
       "19                    \n",
       "Name: Face Amount, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def changeval(ans):\n",
    "    \n",
    "    val = re.sub(\"Face Amount: \",' ',ans)\n",
    "    \n",
    "    val = re.sub(\",\",' ',val)\n",
    "    val = str(re.sub(\" \",'',val))\n",
    "    index = (val.find('$'))\n",
    "    if(index!=-1):\n",
    "        val = val[1:]\n",
    "        \n",
    "    #val = int(val)\n",
    "    return (val)\n",
    "\n",
    "\n",
    "df['Face Amount'] = df['Face Amount'].apply(changeval)\n",
    "df['Face Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FEMALE,1977,41,Product Type: Permanent,50000,200KG, , '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ColumnA'] = df[df.columns[0:11]].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\n",
    "df['ColumnA'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Year_of_birth</th>\n",
       "      <th>Age(years)</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Face Amount</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Habit</th>\n",
       "      <th>Medication</th>\n",
       "      <th>Family</th>\n",
       "      <th>Property</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>ColumnA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FEMALE</td>\n",
       "      <td>1977</td>\n",
       "      <td>41</td>\n",
       "      <td>Product Type: Permanent</td>\n",
       "      <td>50000</td>\n",
       "      <td>200KG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Gender: FEMALE\\nDOB : APR 20, 1977\\nProduct ...</td>\n",
       "      <td>FEMALE,1977,41,Product Type: Permanent,50000,2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>1921</td>\n",
       "      <td>97</td>\n",
       "      <td></td>\n",
       "      <td>250000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Gender: male\\nDOB : 10/00/1921\\nFace Amount:...</td>\n",
       "      <td>male,1921,97, ,250000, , ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>1997</td>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>200 lb</td>\n",
       "      <td>5 Feet</td>\n",
       "      <td></td>\n",
       "      <td>No Medication</td>\n",
       "      <td>('No significant ', 'family', 'history')</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Male\\n01/31/97\\n5' 6Ó\\n200 lb\\nNo medication...</td>\n",
       "      <td>Male,1997,21, ,,200 lb,5 Feet, ,No Medication,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>1945</td>\n",
       "      <td>73</td>\n",
       "      <td></td>\n",
       "      <td>20000</td>\n",
       "      <td>199#</td>\n",
       "      <td>8 Feet</td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Family', 'hx of RA in Mother and Sister....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Seeking $20,000 LN offered Table C due to ch...</td>\n",
       "      <td>Male,1945,73, ,20000,199#,8 Feet,Non-Tobacco,(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Product Type: Permanent</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Male 53\\nBuilt â\\x80\\x93 Preferred NT\\nDiagn...</td>\n",
       "      <td>Male, , ,Product Type: Permanent,, , ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Female</td>\n",
       "      <td>1966</td>\n",
       "      <td>52</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>500212</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('Strong ', 'family', 'history for skin cancer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['General:\\n    -   Client Gender: Female\\n   ...</td>\n",
       "      <td>Female,1966,52,Product Type: Term,500212, , ,T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Female</td>\n",
       "      <td>1996</td>\n",
       "      <td>22</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>50000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Lives', 'in XXXX XXXX, She is a US Citiz...</td>\n",
       "      <td>['Female, DOB 01/03/1996NS looking for $50m te...</td>\n",
       "      <td>Female,1996,22,Product Type: Term,50000000, , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MALE</td>\n",
       "      <td>1950</td>\n",
       "      <td>68</td>\n",
       "      <td></td>\n",
       "      <td>300000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] QQ: S BarXXXX\\n\\nPlease ...</td>\n",
       "      <td>MALE,1950,68, ,300000, , ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Female</td>\n",
       "      <td>1950</td>\n",
       "      <td>68</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>255lb</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] Pascarella Case - Potent...</td>\n",
       "      <td>Female,1950,68, ,,255lb, ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Female</td>\n",
       "      <td>1950</td>\n",
       "      <td>35</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>777000</td>\n",
       "      <td>199 lbs</td>\n",
       "      <td>6.6 Feet</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('Household income is 11K, she is a home maker...</td>\n",
       "      <td>['Subject: [External] XXXXX\\n\\nF/age 35, NS, b...</td>\n",
       "      <td>Female,1950,35,Product Type: Term,777000,199 l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Male</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>555000</td>\n",
       "      <td>196 lbs</td>\n",
       "      <td>5 Feet 9 Inches</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('           Uses it for pleasure and business...</td>\n",
       "      <td>[\"Subject: [External] Tentative case \\n\\nAgent...</td>\n",
       "      <td>Male, , ,Product Type: Term,555000,196 lbs,5 F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Male</td>\n",
       "      <td></td>\n",
       "      <td>22</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>TermYear:22years</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Male- 22 years old state of 50 looking for 2...</td>\n",
       "      <td>Male, ,22,Product Type: Term,TermYear:22years,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Female</td>\n",
       "      <td></td>\n",
       "      <td>33</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External]Female Age 33 \\n\\nThis me...</td>\n",
       "      <td>Female, ,33, ,, , ,Non-Tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>1995</td>\n",
       "      <td>23</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>59000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No Medication</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] QQ - Zvin\\n\\nPer the age...</td>\n",
       "      <td>,1995,23,Product Type: Term,59000000, , , ,No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Male</td>\n",
       "      <td>1995</td>\n",
       "      <td>55</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>1555000</td>\n",
       "      <td>255 lb</td>\n",
       "      <td>6 Feet</td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('Mom had breast cancer at age 65 but all ', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[\"Subject: [External] #secure# Wong quote\\n\\nW...</td>\n",
       "      <td>Male,1995,55,Product Type: Term,1555000,255 lb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>1995</td>\n",
       "      <td>23</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['APS SUMMARY\\nPMH: Subarachnoid Bleed 20X2 no...</td>\n",
       "      <td>,1995,23, ,, , ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Female</td>\n",
       "      <td>1996</td>\n",
       "      <td>22</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>20000000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Lives', 'in XXXX XXXX, She is a US Citiz...</td>\n",
       "      <td>['Subject: [pSpam] DR QQ\\n\\nFemale, DOB 01/XX/...</td>\n",
       "      <td>Female,1996,22,Product Type: Term,20000000, , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Female</td>\n",
       "      <td>1996</td>\n",
       "      <td>55</td>\n",
       "      <td>Product Type: Term</td>\n",
       "      <td>TermYear:20year</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Non-Smoker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Subject: [External] Quick quote request - FM...</td>\n",
       "      <td>Female,1996,55,Product Type: Term,TermYear:20y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Male</td>\n",
       "      <td>1999</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>199#</td>\n",
       "      <td></td>\n",
       "      <td>Non-Tobacco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>('', 'Family', 'hx of RA in Mother and Sister....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['LN offered Table C due to chronic pain histo...</td>\n",
       "      <td>Male,1999,19, ,,199#, ,Non-Tobacco,('', 'Famil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender Year_of_birth Age(years)             Product Type  \\\n",
       "1   FEMALE          1977         41  Product Type: Permanent   \n",
       "2     male          1921         97                            \n",
       "3     Male          1997         21                            \n",
       "4     Male          1945         73                            \n",
       "5     Male                           Product Type: Permanent   \n",
       "6   Female          1966         52       Product Type: Term   \n",
       "7   Female          1996         22       Product Type: Term   \n",
       "8     MALE          1950         68                            \n",
       "9   Female          1950         68                            \n",
       "10  Female          1950         35       Product Type: Term   \n",
       "11    Male                                Product Type: Term   \n",
       "12    Male                       22       Product Type: Term   \n",
       "13  Female                       33                            \n",
       "14                  1995         23       Product Type: Term   \n",
       "15    Male          1995         55       Product Type: Term   \n",
       "16                  1995         23                            \n",
       "17  Female          1996         22       Product Type: Term   \n",
       "18  Female          1996         55       Product Type: Term   \n",
       "19    Male          1999         19                            \n",
       "\n",
       "         Face Amount   Weight           Height        Habit     Medication  \\\n",
       "1              50000    200KG                                          NaN   \n",
       "2             250000                                                   NaN   \n",
       "3                      200 lb           5 Feet               No Medication   \n",
       "4              20000     199#           8 Feet  Non-Tobacco            NaN   \n",
       "5                                                                      NaN   \n",
       "6             500212                                Tobacco            NaN   \n",
       "7           50000000                            Non-Tobacco            NaN   \n",
       "8             300000                                                   NaN   \n",
       "9                       255lb                                          NaN   \n",
       "10            777000  199 lbs         6.6 Feet                         NaN   \n",
       "11            555000  196 lbs  5 Feet 9 Inches   Non-Smoker            NaN   \n",
       "12  TermYear:22years                                                   NaN   \n",
       "13                                              Non-Tobacco            NaN   \n",
       "14          59000000                                         No Medication   \n",
       "15           1555000   255 lb           6 Feet   Non-Smoker            NaN   \n",
       "16                                                                     NaN   \n",
       "17          20000000                                                   NaN   \n",
       "18   TermYear:20year                             Non-Smoker            NaN   \n",
       "19                       199#                   Non-Tobacco            NaN   \n",
       "\n",
       "                                               Family  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3            ('No significant ', 'family', 'history')   \n",
       "4   ('', 'Family', 'hx of RA in Mother and Sister....   \n",
       "5                                                 NaN   \n",
       "6   ('Strong ', 'family', 'history for skin cancer...   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15  ('Mom had breast cancer at age 65 but all ', '...   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19  ('', 'Family', 'hx of RA in Mother and Sister....   \n",
       "\n",
       "                                             Property  \\\n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7   ('', 'Lives', 'in XXXX XXXX, She is a US Citiz...   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10  ('Household income is 11K, she is a home maker...   \n",
       "11  ('           Uses it for pleasure and business...   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17  ('', 'Lives', 'in XXXX XXXX, She is a US Citiz...   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "\n",
       "                                          Unnamed: 11  \\\n",
       "1   ['Gender: FEMALE\\nDOB : APR 20, 1977\\nProduct ...   \n",
       "2   ['Gender: male\\nDOB : 10/00/1921\\nFace Amount:...   \n",
       "3   [\"Male\\n01/31/97\\n5' 6Ó\\n200 lb\\nNo medication...   \n",
       "4   [\"Seeking $20,000 LN offered Table C due to ch...   \n",
       "5   ['Male 53\\nBuilt â\\x80\\x93 Preferred NT\\nDiagn...   \n",
       "6   ['General:\\n    -   Client Gender: Female\\n   ...   \n",
       "7   ['Female, DOB 01/03/1996NS looking for $50m te...   \n",
       "8   ['Subject: [External] QQ: S BarXXXX\\n\\nPlease ...   \n",
       "9   ['Subject: [External] Pascarella Case - Potent...   \n",
       "10  ['Subject: [External] XXXXX\\n\\nF/age 35, NS, b...   \n",
       "11  [\"Subject: [External] Tentative case \\n\\nAgent...   \n",
       "12  ['Male- 22 years old state of 50 looking for 2...   \n",
       "13  ['Subject: [External]Female Age 33 \\n\\nThis me...   \n",
       "14  ['Subject: [External] QQ - Zvin\\n\\nPer the age...   \n",
       "15  [\"Subject: [External] #secure# Wong quote\\n\\nW...   \n",
       "16  ['APS SUMMARY\\nPMH: Subarachnoid Bleed 20X2 no...   \n",
       "17  ['Subject: [pSpam] DR QQ\\n\\nFemale, DOB 01/XX/...   \n",
       "18  ['Subject: [External] Quick quote request - FM...   \n",
       "19  ['LN offered Table C due to chronic pain histo...   \n",
       "\n",
       "                                              ColumnA  \n",
       "1   FEMALE,1977,41,Product Type: Permanent,50000,2...  \n",
       "2                         male,1921,97, ,250000, , ,   \n",
       "3   Male,1997,21, ,,200 lb,5 Feet, ,No Medication,...  \n",
       "4   Male,1945,73, ,20000,199#,8 Feet,Non-Tobacco,(...  \n",
       "5             Male, , ,Product Type: Permanent,, , ,   \n",
       "6   Female,1966,52,Product Type: Term,500212, , ,T...  \n",
       "7   Female,1996,22,Product Type: Term,50000000, , ...  \n",
       "8                         MALE,1950,68, ,300000, , ,   \n",
       "9                         Female,1950,68, ,,255lb, ,   \n",
       "10  Female,1950,35,Product Type: Term,777000,199 l...  \n",
       "11  Male, , ,Product Type: Term,555000,196 lbs,5 F...  \n",
       "12  Male, ,22,Product Type: Term,TermYear:22years,...  \n",
       "13                     Female, ,33, ,, , ,Non-Tobacco  \n",
       "14   ,1995,23,Product Type: Term,59000000, , , ,No...  \n",
       "15  Male,1995,55,Product Type: Term,1555000,255 lb...  \n",
       "16                                  ,1995,23, ,, , ,   \n",
       "17  Female,1996,22,Product Type: Term,20000000, , ...  \n",
       "18  Female,1996,55,Product Type: Term,TermYear:20y...  \n",
       "19  Male,1999,19, ,,199#, ,Non-Tobacco,('', 'Famil...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the Pre-Processed File\n",
    "\n",
    "\n",
    "\n",
    "#process_data(name)\n",
    "\n",
    "#df = pd.read_csv(\"Processed_Data.csv\", encoding='ISO-8859-1')\n",
    "#df[\"Processed\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords,wordnet as wn\n",
    "from nltk.tokenize import wordpunct_tokenize,sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removes all punctuations which acts as noise\n",
    "\n",
    "def rem_punt(doc):\n",
    "    ans = re.sub('\"|\\\\n|\\(|\\)|\\.|[$!--+@#:]',' ',doc)\n",
    "    ans = re.sub(' +',' ',ans)\n",
    "    ans = ans.lower()\n",
    "    return ans\n",
    "\n",
    "\n",
    "# Stop words removal using tokenization\n",
    "\n",
    "stop_word = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize(document): \n",
    "    lemmy = []\n",
    "    for sent in sent_tokenize(document):\n",
    "        for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "            #print(token,tag)\n",
    "            if token in stop_word:\n",
    "                 continue\n",
    "            lemma = lemmatize(token, tag)\n",
    "            lemmy.append(lemma)\n",
    "    return lemmy\n",
    "\n",
    "#Lemmatization for tokens simplification\n",
    "\n",
    "def lemmatize(token, tag):\n",
    "    tag = {\n",
    "          'N': wn.NOUN,\n",
    "          'V': wn.VERB,\n",
    "          'R': wn.ADV,\n",
    "          'J': wn.ADJ\n",
    "    }.get(tag[0], wn.NOUN)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(token, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[22]:\n",
    "\n",
    "df['Lemmitize'] = df['ColumnA'].apply(rem_punt).apply(tokenize)\n",
    "\n",
    "\n",
    "df.to_csv('NLPProcessed.csv',index=False, encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[25]:\n",
    "\n",
    "df = pd.read_csv('NLPProcessed.csv')\n",
    "\n",
    "\n",
    "# # Statistical Modeling \n",
    "\n",
    "# In[26]:\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer,LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "X = df['Lemmitize']\n",
    "of = pd.read_csv('raw_data1.csv', encoding='ISO-8859-1')\n",
    "y = of['Offer']\n",
    "#y = df['Offer_noise_free']\n",
    "#lab_y = LabelEncoder()\n",
    "#y = lab_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['female', '1977', '41', 'product', 'type', 'permanent', '50000', '200kg']\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[29]:\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "vect = TfidfVectorizer(max_df=0.8, max_features=15000, min_df=0.01, use_idf=True , ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt \\n%matplotlib inline\\nplt.spy(vect)\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "#model1 = XGBClassifier(nthread=4,n_estimators=1000)\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "model2 = GaussianNB()\n",
    "\n",
    "\n",
    "# ExtraTree Classifier\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "model3 = RandomForestClassifier(n_estimators=60,n_jobs=3,max_features = \"auto\", min_samples_leaf = 50)\n",
    "\n",
    "# SVM Classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model4 = SVC(kernel='rbf', C=100,gamma=10)\n",
    "\n",
    "\n",
    "# Logistic Regression \n",
    "\n",
    "from sklearn.linear_model import LinearRegression,SGDClassifier,LogisticRegression\n",
    "model5 = LogisticRegression()\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model6 = LinearDiscriminantAnalysis()\n",
    "\n",
    "from sklearn import linear_model\n",
    "model7 = linear_model.SGDClassifier()\n",
    "'''\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "plt.spy(vect)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def model_saving(model_name,model):\n",
    "    filename = model_name +'.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Fitting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "\n",
    "name = [] \n",
    "results = []\n",
    "matrix_confusion = []\n",
    "training_time = []\n",
    "prediction_time = []\n",
    "\n",
    "def model_making(model_name, vect , model , X_train , y_train , X_test , y_test):\n",
    "    \n",
    "    t1 =time.time()\n",
    "    clf = make_pipeline(vect,model)\n",
    "    clf.fit(X_train,y_train)\n",
    "    t2 = time.time()\n",
    "    training_time.append(t2-t1)\n",
    "    model_saving(model_name,clf)\n",
    "    t1 = time.time()\n",
    "    pd = clf.predict(X_test)\n",
    "    t2 = time.time()\n",
    "    prediction_time.append(t2-t1)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    name.append(model_name)\n",
    "    results.append(accuracy_score(y_test, y_pred)*100)\n",
    "    matrix_confusion.append(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    #print (\"=====Accuracy Score \", \"{0:.2f}\".format(accuracy_score(y_test, y_pred)*100), \"%\")\n",
    "    #print (\"=====Confusion Matrix\")\n",
    "    #print (confusion_matrix(y_test, y_pred))\n",
    "    #target_names = ['class 0', 'class 1', 'class 2']\n",
    "    #print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_making(\"Random Forest\",vect, model3, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_making(\"SVM\" , vect, model4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_making(\"Logistic Regression\",vect, model5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_making(\"SGDClassifier\",vect, model7, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model_making(\"Naive Bayes\", vect , model2 , X_train, y_train, X_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset 19\n",
      "Training dataset:  14\n",
      "Testing dataset:  5 \n",
      "\n",
      "Name                       Accuracy         Training Time(s)    Prediction Time(s) \n",
      " \n",
      "Random Forest               40.000               0.220                        0.107s \n",
      " \n",
      "SVM                         40.000               0.009                        0.002s \n",
      " \n",
      "Logistic Regression         0.000                0.009                        0.002s \n",
      " \n",
      "SGDClassifier               0.000                0.089                        0.003s \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Total dataset\",len(X))\n",
    "print(\"Training dataset: \",len(X_train))\n",
    "print(\"Testing dataset: \",len(X_test),\"\\n\")\n",
    "print(\"{:20} {:^20} {:^20} {:^20}\\n \".format(\"Name\" , \"Accuracy\" , \"Training Time(s)\" , \"Prediction Time(s)\" ) )\n",
    "\n",
    "for i in range(len(name)):\n",
    "    print(\"{:20} {:^20.3f} {:^20.3f} {:20.3f}s \\n \".format(name[i] , results[i] , training_time[i] , prediction_time[i] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7                      ['male', '1950', '68', '300000']\n",
       "9     ['female', '1950', '35', 'product', 'type', 't...\n",
       "3     ['male', '1945', '73', '20000', '199', '8', 'f...\n",
       "18    ['male', '1999', '19', '199', 'non', 'tobacco'...\n",
       "6     ['female', '1996', '22', 'product', 'type', 't...\n",
       "Name: Lemmitize, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('SVM.sav', 'rb'))\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: \"['male', '1921', '97', '250000']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-119-3ad260e86b39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgridS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgridS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgridS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=====Accuracy Score \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"{0:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \"\"\"\n\u001b[1;32m--> 945\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[0;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m--> 564\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    380\u001b[0m                                       force_all_finite)\n\u001b[0;32m    381\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: \"['male', '1921', '97', '250000']\""
     ]
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gridS = GridSearchCV(model4, parameters)\n",
    "gridS.fit(X_train,y_train)\n",
    "y_pred = gridS.predict(X_test)\n",
    "print(\"=====Accuracy Score \", \"{0:.2f}\".format(accuracy_score(y_test, y_pred)*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
